{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYYVi65886AXLrtsKOxOmU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansar2019/image-captionig/blob/main/Copie_de_analysecaption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCpJG3KEwvEc"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/OFA.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/BLIP2.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "id": "mk1JSDq3yUWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/Fuyu_8B.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "id": "DE4kN_KQyX5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/LLaVA.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "id": "VXgAGOCryb6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/VITGPT2.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "id": "Ffzry9VMygJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/kosmos-2.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "id": "f6SmH-rEygpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/moondream2_captions.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "id": "PT2cL7npyhCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/GITCaption.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "id": "6T_kiPdNz9sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/uform-gen.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "id": "710dymQn0C7k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
