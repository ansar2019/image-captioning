{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM04H4bay/SsK00fEymyxz4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansar2019/image-captionig/blob/main/deepseek_vl2_tiny.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrsUMo7IJbxh",
        "outputId": "f6d96824-3174-492d-dd6f-473c3223b264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "-e option requires 1 argument\n"
          ]
        }
      ],
      "source": [
        "!pip install -e\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepseek-vl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MpPMuCBJ7S5",
        "outputId": "a28d906a-d91e-41eb-dedf-237df94c1795"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepseek-vl\n",
            "  Downloading deepseek_vl-0.0.1.dev0-py3-none-any.whl.metadata (365 bytes)\n",
            "Downloading deepseek_vl-0.0.1.dev0-py3-none-any.whl (1.1 kB)\n",
            "Installing collected packages: deepseek-vl\n",
            "Successfully installed deepseek-vl-0.0.1.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepseek-vl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2jO-u7DKFtB",
        "outputId": "da46d807-f83e-40f9-ba1d-1fa0b8a7d6c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepseek-vl in /usr/local/lib/python3.11/dist-packages (0.0.1.dev0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepseek-vl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV2SsEcJKP_S",
        "outputId": "a05a0aa3-88d3-49df-baba-b42b075f9fd7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepseek-vl in /usr/local/lib/python3.11/dist-packages (0.0.1.dev0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "from deepseek_vl.models import DeepseekVLV2Processor, DeepseekVLV2ForCausalLM\n",
        "from deepseek_vl.utils.io import load_pil_images\n",
        "\n",
        "\n",
        "# specify the path to the model\n",
        "model_path = \"deepseek-ai/deepseek-vl2-small\"\n",
        "vl_chat_processor: DeepseekVLV2Processor = DeepseekVLV2Processor.from_pretrained(model_path)\n",
        "tokenizer = vl_chat_processor.tokenizer\n",
        "\n",
        "vl_gpt: DeepseekVLV2ForCausalLM = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
        "vl_gpt = vl_gpt.to(torch.bfloat16).cuda().eval()\n",
        "\n",
        "## single image conversation example\n",
        "conversation = [\n",
        "    {\n",
        "        \"role\": \"<|User|>\",\n",
        "        \"content\": \"<image>\\n<|ref|>The giraffe at the back.<|/ref|>.\",\n",
        "        \"images\": [\"./images/visual_grounding.jpeg\"],\n",
        "    },\n",
        "    {\"role\": \"<|Assistant|>\", \"content\": \"\"},\n",
        "]\n",
        "\n",
        "## multiple images (or in-context learning) conversation example\n",
        "# conversation = [\n",
        "#     {\n",
        "#         \"role\": \"User\",\n",
        "#         \"content\": \"<image_placeholder>A dog wearing nothing in the foreground, \"\n",
        "#                    \"<image_placeholder>a dog wearing a santa hat, \"\n",
        "#                    \"<image_placeholder>a dog wearing a wizard outfit, and \"\n",
        "#                    \"<image_placeholder>what's the dog wearing?\",\n",
        "#         \"images\": [\n",
        "#             \"images/dog_a.png\",\n",
        "#             \"images/dog_b.png\",\n",
        "#             \"images/dog_c.png\",\n",
        "#             \"images/dog_d.png\",\n",
        "#         ],\n",
        "#     },\n",
        "#     {\"role\": \"Assistant\", \"content\": \"\"}\n",
        "# ]\n",
        "\n",
        "# load images and prepare for inputs\n",
        "pil_images = load_pil_images(conversation)\n",
        "prepare_inputs = vl_chat_processor(\n",
        "    conversations=conversation,\n",
        "    images=pil_images,\n",
        "    force_batchify=True,\n",
        "    system_prompt=\"\"\n",
        ").to(vl_gpt.device)\n",
        "\n",
        "# run image encoder to get the image embeddings\n",
        "inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
        "\n",
        "# run the model to get the response\n",
        "outputs = vl_gpt.language_model.generate(\n",
        "    inputs_embeds=inputs_embeds,\n",
        "    attention_mask=prepare_inputs.attention_mask,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    bos_token_id=tokenizer.bos_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    max_new_tokens=512,\n",
        "    do_sample=False,\n",
        "    use_cache=True\n",
        ")\n",
        "\n",
        "answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
        "print(f\"{prepare_inputs['sft_format'][0]}\", answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "IZpOV4KPJpSH",
        "outputId": "964b7666-857a-493b-9359-9238adf2fbb3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'deepseek_vl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e40ac480a802>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepseek_vl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepseekVLV2Processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeepseekVLV2ForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepseek_vl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_pil_images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deepseek_vl'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}