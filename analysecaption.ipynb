{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPs/bYYJmj1YzBkyyicTKwF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansar2019/image-captionig/blob/main/analysecaption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCpJG3KEwvEc",
        "outputId": "ee4885fa-b0f6-4051-ad90-515380f96ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Model: Unknown**\n",
            "  - Location: 97.7%\n",
            "  - Manner: 10.1%\n",
            "  - Reason: 0.0%\n",
            "  - Time: 1.2%\n",
            "  - Dominant Focus: **location**\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/OFA.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/BLIP2.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk1JSDq3yUWr",
        "outputId": "c2435fdb-59ef-4b96-e0a4-2a4663996ee4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Model: Unknown**\n",
            "  - Location: 85.4%\n",
            "  - Manner: 3.3%\n",
            "  - Reason: 0.0%\n",
            "  - Time: 0.2%\n",
            "  - Dominant Focus: **location**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/Fuyu_8B.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE4kN_KQyX5j",
        "outputId": "c1985287-bc92-4f89-ed1d-b5192dbba798"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Model: Unknown**\n",
            "  - Location: 98.4%\n",
            "  - Manner: 70.8%\n",
            "  - Reason: 9.3%\n",
            "  - Time: 17.0%\n",
            "  - Dominant Focus: **location**\n",
            "\n",
            "**Model: 072[b'In the image, there are two people**\n",
            "  - Location: 100.0%\n",
            "  - Manner: 100.0%\n",
            "  - Reason: 0.0%\n",
            "  - Time: 0.0%\n",
            "  - Dominant Focus: **location**\n",
            "\n",
            "**Model: 183[b'In the image, there are two dogs**\n",
            "  - Location: 0.0%\n",
            "  - Manner: 0.0%\n",
            "  - Reason: 0.0%\n",
            "  - Time: 0.0%\n",
            "  - Dominant Focus: **location**\n",
            "\n",
            "**Model: 205[b'In the image, there are two horses**\n",
            "  - Location: 100.0%\n",
            "  - Manner: 100.0%\n",
            "  - Reason: 0.0%\n",
            "  - Time: 0.0%\n",
            "  - Dominant Focus: **location**\n",
            "\n",
            "**Model: 263[b'In the image, there are two horses**\n",
            "  - Location: 100.0%\n",
            "  - Manner: 100.0%\n",
            "  - Reason: 0.0%\n",
            "  - Time: 0.0%\n",
            "  - Dominant Focus: **location**\n",
            "\n",
            "**Model: 292[b'In the image, there are two objects**\n",
            "  - Location: 100.0%\n",
            "  - Manner: 100.0%\n",
            "  - Reason: 0.0%\n",
            "  - Time: 0.0%\n",
            "  - Dominant Focus: **location**\n",
            "\n",
            "**Model: 465[b'In the image, there are two people**\n",
            "  - Location: 100.0%\n",
            "  - Manner: 100.0%\n",
            "  - Reason: 0.0%\n",
            "  - Time: 100.0%\n",
            "  - Dominant Focus: **location**\n",
            "\n",
            "**Model: 564[b'In the image, there are two buses**\n",
            "  - Location: 100.0%\n",
            "  - Manner: 100.0%\n",
            "  - Reason: 0.0%\n",
            "  - Time: 100.0%\n",
            "  - Dominant Focus: **location**\n",
            "\n",
            "**Model: 660[b'The image features three vintage refrigerators, each with a different color**\n",
            "  - Location: 100.0%\n",
            "  - Manner: 0.0%\n",
            "  - Reason: 0.0%\n",
            "  - Time: 0.0%\n",
            "  - Dominant Focus: **location**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/LLaVA.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXgAGOCryb6p",
        "outputId": "17fa0209-bad8-40a0-c2c9-2caaf2b7475d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Model: Unknown**\n",
            "  - Location: 100.0%\n",
            "  - Manner: 85.6%\n",
            "  - Reason: 16.3%\n",
            "  - Time: 26.1%\n",
            "  - Dominant Focus: **location**\n",
            "\n",
            "**Model: 823['The image depicts a city street with a black bus driving down the road. The bus is positioned in the middle of the scene, with a tall building in the background. The street is lined with buildings, and there are several traffic lights along the way.\\n\\nIn addition to the bus, there are two other vehicles visible in the scene**\n",
            "  - Location: 100.0%\n",
            "  - Manner: 100.0%\n",
            "  - Reason: 0.0%\n",
            "  - Time: 100.0%\n",
            "  - Dominant Focus: **location**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/VITGPT2.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffzry9VMygJm",
        "outputId": "68eb0ce8-189c-4955-e392-be767a8c9226"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Model: Unknown**\n",
            "  - Location: 96.6%\n",
            "  - Manner: 6.2%\n",
            "  - Reason: 0.0%\n",
            "  - Time: 0.9%\n",
            "  - Dominant Focus: **location**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/kosmos-2.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6SmH-rEygpB",
        "outputId": "bddcb75a-1372-40d8-edef-f660600c55eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Model: Unknown**\n",
            "  - Location: 100.0%\n",
            "  - Manner: 1.9%\n",
            "  - Reason: 0.1%\n",
            "  - Time: 2.3%\n",
            "  - Dominant Focus: **location**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/moondream.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT2cL7npyhCM",
        "outputId": "bdc16560-fe4e-4734-8da5-d918d1ce72f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Model: Unknown**\n",
            "  - Location: 100.0%\n",
            "  - Manner: 47.5%\n",
            "  - Reason: 5.0%\n",
            "  - Time: 20.0%\n",
            "  - Dominant Focus: **location**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/GITCaption.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T_kiPdNz9sC",
        "outputId": "ed0f56ef-ac7f-42d8-9ef0-127898ccf2c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Model: Unknown**\n",
            "  - Location: 96.3%\n",
            "  - Manner: 8.4%\n",
            "  - Reason: 0.1%\n",
            "  - Time: 1.0%\n",
            "  - Dominant Focus: **location**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import defaultdict\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(sentence):\n",
        "    \"\"\"Extract WH components (subject, verb, location, manner, reason, time) from a sentence.\"\"\"\n",
        "    doc = nlp(sentence)\n",
        "    components = {\n",
        "        \"subject\": [],\n",
        "        \"verb\": [],\n",
        "        \"location\": False,\n",
        "        \"manner\": False,\n",
        "        \"reason\": False,\n",
        "        \"time\": False\n",
        "    }\n",
        "\n",
        "    # Subject and Verb extraction\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            components[\"subject\"].append(token.text)\n",
        "        if token.dep_ == \"ROOT\" and token.pos_ == \"VERB\":\n",
        "            components[\"verb\"].append(token.text)\n",
        "\n",
        "    # Location (prepositional phrases)\n",
        "    components[\"location\"] = any(token.dep_ == \"prep\" for token in doc)\n",
        "\n",
        "    # Manner (adverbs)\n",
        "    components[\"manner\"] = any(token.pos_ == \"ADV\" for token in doc)\n",
        "\n",
        "    # Reason (conjunctions like \"because\", \"since\")\n",
        "    components[\"reason\"] = any(token.text.lower() in {\"because\", \"since\", \"as\", \"due to\"} for token in doc)\n",
        "\n",
        "    # Time (temporal nouns or prepositions like \"during\", \"while\")\n",
        "    components[\"time\"] = any(\n",
        "        token.text.lower() in {\"while\", \"during\", \"when\", \"after\", \"before\"} or\n",
        "        token.ent_type_ == \"TIME\" for token in doc\n",
        "    )\n",
        "\n",
        "    return components\n",
        "\n",
        "def analyze_captions(file_path):\n",
        "    \"\"\"Analyze a .txt file of captions and generate a model focus report.\"\"\"\n",
        "    model_stats = defaultdict(lambda: {\n",
        "        \"total\": 0, \"location\": 0, \"manner\": 0, \"reason\": 0, \"time\": 0\n",
        "    })\n",
        "\n",
        "    with open(file_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Split model name and caption (assuming format: \"Model: Caption\")\n",
        "            if \": \" in line:\n",
        "                model, caption = line.split(\": \", 1)\n",
        "            else:\n",
        "                model = \"Unknown\"\n",
        "                caption = line\n",
        "\n",
        "            # Parse the caption\n",
        "            components = parse_sentence(caption)\n",
        "            model_stats[model][\"total\"] += 1\n",
        "            for key in [\"location\", \"manner\", \"reason\", \"time\"]:\n",
        "                if components[key]:\n",
        "                    model_stats[model][key] += 1\n",
        "\n",
        "    # Generate report\n",
        "    report = []\n",
        "    for model, stats in model_stats.items():\n",
        "        total = stats[\"total\"]\n",
        "        if total == 0:\n",
        "            continue\n",
        "\n",
        "        percentages = {\n",
        "            \"location\": (stats[\"location\"] / total) * 100,\n",
        "            \"manner\": (stats[\"manner\"] / total) * 100,\n",
        "            \"reason\": (stats[\"reason\"] / total) * 100,\n",
        "            \"time\": (stats[\"time\"] / total) * 100\n",
        "        }\n",
        "        dominant = max(percentages, key=percentages.get)\n",
        "\n",
        "        report.append(\n",
        "            f\"**Model: {model}**\\n\"\n",
        "            f\"  - Location: {percentages['location']:.1f}%\\n\"\n",
        "            f\"  - Manner: {percentages['manner']:.1f}%\\n\"\n",
        "            f\"  - Reason: {percentages['reason']:.1f}%\\n\"\n",
        "            f\"  - Time: {percentages['time']:.1f}%\\n\"\n",
        "            f\"  - Dominant Focus: **{dominant}**\\n\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Run analysis\n",
        "file_path = \"/content/uform-gen.txt\"  # Replace with your file path\n",
        "print(analyze_captions(file_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "710dymQn0C7k",
        "outputId": "d7a79fc6-77e8-4737-9e64-ea6ec46a327e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Model: Unknown**\n",
            "  - Location: 100.0%\n",
            "  - Manner: 81.4%\n",
            "  - Reason: 20.9%\n",
            "  - Time: 10.2%\n",
            "  - Dominant Focus: **location**\n",
            "\n"
          ]
        }
      ]
    }
  ]
}